---
title: "AlexNet 图像分类网络搭建教程"
date: 2025-10-23
categories:
  - 教程
tags:
  - 深度学习
  - PyTorch
  - 神经网络
  - AlexNet
  - 计算机视觉
  - 图像分类
toc: true
toc_label: "目录"
toc_sticky: true
header:
  teaser: /assets/images/alexnet/alexnet-banner.jpg
---

jetson 上搭建 AlexNet 图像分类网络

-- 文档内容为学习记录，整理来源于网络，仅用于个人学习

> 本文档共同整理者：zbr1234 

### AlexNet搭建

#### 3.1 网络概述

![img]({{ '/assets/images/alexnet/v2-29dee95d137bf99db695a0c916c6c24c_1440w.jpg' | relative_url }})

相对于LeNet主要改进：

1.随机丢弃(**Dropout**)正则化

2.**ReLu**：激活层从sigmoid变成ReLu（减缓梯度消失）

3.最大池化层(**MaxPooling**)应用

<img src="{{ '/assets/images/alexnet/image-20240911155921306-1741244961713-3.png' | relative_url }}" alt="image-20240911155921306" style="zoom: 50%;" />

#### 3.2 文件结构说明

```工程结构
Alex/
├── data/                     # 数据集目录(split_data.py运行后自动生成)
│   ├── train/                # 训练集目录
│   └── val/                  # 验证集目录
├── PetImages/                # 原始图片目录（由Cats_vs_Dogs.zip解压而来）
│   ├── Cat/                  # 猫类图片
│   └── Dog/                  # 狗类图片
├── predict/                  # 预测集目录
│   ├── Cat/                  # 猫类预测图片
│   └── Dog/                  # 狗类预测图片
├── save_model/               # 模型保存目录
│   ├── best_model.pth        # 训练出来的最优模型（train.py训练时生成）
│   └── last_model.pth		  # 训练出来的最后一个模型（train.py训练时生成）
├── PetImages.zip             # 压缩的模型文件或数据文件（下载的数据集压缩包）
├── net.py                    # 网络模型定义文件
├── split_data.py             # 数据集划分脚本
├── test.py                   # 测试脚本
└── train.py                  # 训练脚本
```



#### 3.3 搭建过程



##### 3.3.1 数据集的获取

【工程文件】

百度网盘链接：https://pan.baidu.com/s/1uODTF-CZGbD3mBR2WQgYzg?pwd=u8xk 
提取码：u8xk

![image-20240912190643058]({{ '/assets/images/alexnet/image-20240912190643058-1741244961713-4.png' | relative_url }})

我们的数据集名称为“PetImages.zip”，这里面是分类好的猫和狗的图片。这里我们的数据集是在caggle网站上获取的，由于网站不好进入，我们这下载在工程文件里面的。

- 数据集的解压办法：在当前工程同样也是“PetImages.zip”压缩包位置的路径的命令框中使用解压指令


```terminal
unzip PetImages.zip
```

解压完成后应该在改目录下生成一个“PetImages”文件夹，里面是两个Cat 和Dog文件夹是分类好的猫和狗图片。

然后在工程文件夹里导入图片数据文件夹，里面需要有名为“Cat”、“Dog”的文件夹，里面装的是分类好的猫和狗的图片。这里我们的数据集是在caggle网站上获取的，由于网站不好进入，我们这下载在工程文件里面的data_name文件夹。    



##### 3.3.2 数据集的划分

- 运行写好的split_data.py，会将数据集的数据按比例划分为训练集和测试集。


```terminal
/usr/bin/python3.9 /home/jetson/PycharmProjects/Alex/split_data.py 
[Cat] processing [12501/12501]
[Dog] processing [12501/12501]
processing done!

Process finished with exit code 0
```

这里就分好了训练集和测试集，但经过我们后面训的操作会发现可能会存在点问题，就是数据集中会出现一些图片是无法识别的这需要手动删除一些错误图片，比如后面训练的时候发生报错

```terminal
FileNotFoundError: Found no valid file for the classes MSR-LA - 666.jpg, PetImages, readme[1].txt. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp
```

![18de3cf772fd0cddb90140124f90f052]({{ '/assets/images/alexnet/18de3cf772fd0cddb90140124f90f052.png' | relative_url }})

链接中的的“PetImages.zip”里的图片经过筛查应该不会有无效图片，若有请手动删除。

**这里有个需要注意的地方，split_data注意不要多次运行**！！不然训练集和测试集的图片数量可能会比8:2要多，可以检查一下训练集与测试集的图片数量是否合理，训练集应该有20002左右的items，验证集为5000左右。

<img src="{{ '/assets/images/alexnet/image-20250303210538503.png' | relative_url }}" alt="image-20250303210538503" style="zoom:50%;" />



##### 3.3.3 模型的训练

- 编写train.py

- 修改train.py里面的ROOT的地址为数据集的训练集和测试集相对地址。


```python
ROOT_TRAIN = "./data/train"
ROOT_TEST = "./data/val"
```

- 运行train.py文件，模型训练好后能得到损失和精度趋势图，并自动将精度最高和最后一轮的模型保存到自动生成的“save_model”文件夹里。


训练时间比较长，预计有一个半小时。如果觉得时间过长可以通过以下办法简化训练过程：

1.减少训练循环次数epoch

```python
epoch = 20
```

可以将epoch 设置为15或者10，这样训练的次数会减少，可能模型并不是最佳的，但也表现不错（在10轮之后就已经收敛的很好了）。

2.减少数据集的数量

删除一定比例的训练集和验证集里猫狗的图片数量，比如删掉30%.



**模型训练的结果**：

```terminal
epoch19
-----------
train_loss0.10579887324050069
train_acc0.9596
val_loss0.41070800269864927
val_acc0.8739384291278329
epoch20
-----------
train_loss0.05440913660312072
train_acc0.98115
val_loss0.42272428810376983
val_acc0.8877388535031847
save best model, 第20轮
```

可以看出来最终最好的模型保存的是第20轮训练出来的模型，模型在验证集的精确度高达0.888

**训练集和验证集损失函数走势图**

<img src="{{ '/assets/images/alexnet/Figure_loss.png' | relative_url }}" alt="Figure_loss" style="zoom:67%;" />

**训练集和验证集精确度走势图**

<img src="{{ '/assets/images/alexnet/Figure_acc.png' | relative_url }}" alt="Figure_acc" style="zoom:67%;" />

我们再测试了100个样本最终有95个标记正确，正确率为95%。



#### 3.4 模型的验证与预测

- **编写test.py**

- **建立预测集**。预测集文件夹名字可以叫做"my_pictures",但是里面必须包含"Cat"和"Dog"两个文件夹（注意区此处分大小写），分别放置分类好自己获取的猫和狗图片。

- 先修改test.py里面的数据集的路径


```python
# 设置数据集的路径
ROOT_TRAIN = "data/train"
ROOT_TEST = "my_pictures"
```

这里如果没有自己获取想要测试的照片可以将测试集的路径设置为验证集，拿验证集的图片看看效果

```python
ROOT_TEST = "data/val"
```

- 设置预测猫和狗的图片数量


```python
# 设置猫和狗的图片数量
cat_images = [img for img, label in val_dataset if label == 0]
dog_images = [img for img, label in val_dataset if label == 1]
```

- **选择模型**（可以选择训练出来“save_model“文件夹里的best_model.pth或者last_model.pth）后运行测试，可以通过比对预测结果和实际标记看最终的预测效果。

```python
# 加载模型
model.load_state_dict(torch.load("save_model/best_model.pth"))
```

- 最后运行test.py就能看到最终的预测效果


```terminal
Image Name: 野生猫学长.png, Image Path: my_pictures/Cat/图书馆猫学长.png
predicted: "cat", Actual: "cat"
```

<img src="{{ '/assets/images/alexnet/42d4a8179bf1e63297c8a6d6f7d058e9.png' | relative_url }}" alt="42d4a8179bf1e63297c8a6d6f7d058e9" style="zoom: 10%;" />  



#### 3.5 代码附录

##### **1.net.py**

```python
import torch
from torch import nn
import torch.nn.functional as F

class MyAlexNet(nn.Module):
    def __init__(self):
        super(MyAlexNet, self).__init__()
        self.c1 = nn.Conv2d(in_channels=3, out_channels=48, kernel_size=11, stride=4, padding=2)
        self.ReLU = nn.ReLU()
        self.c2 = nn.Conv2d(in_channels=48, out_channels=128, kernel_size=5, stride=1, padding=2)
        self.s2 = nn.MaxPool2d(2)
        self.c3 = nn.Conv2d(in_channels=128, out_channels=192, kernel_size=3, stride=1, padding=1)
        self.s3 = nn.MaxPool2d(2)
        self.c4 = nn.Conv2d(in_channels=192, out_channels=192, kernel_size=3, stride=1, padding=1)
        self.c5 = nn.Conv2d(in_channels=192, out_channels=128, kernel_size=3, stride=1, padding=1)
        self.s5 = nn.MaxPool2d(kernel_size=3, stride=2)
        self.flatten = nn.Flatten()
        self.f6 = nn.Linear(4608, 2048)
        self.f7 = nn.Linear(2048, 2048)
        self.f8 = nn.Linear(2048, 1000)
        self.f9 = nn.Linear(1000, 2)

    def forward(self, x):
        x = self.ReLU(self.c1(x))
        x = self.ReLU(self.c2(x))
        x = self.s2(x)
        x = self.ReLU(self.c3(x))
        x = self.s3(x)
        x = self.ReLU(self.c4(x))
        x = self.ReLU(self.c5(x))
        x = self.s5(x)
        x = self.flatten(x)
        x = self.f6(x)
        x = F.dropout(x, p=0.5)
        x = self.f7(x)
        x = F.dropout(x, p=0.5)
        x = self.f8(x)
        x = F.dropout(x, p=0.5)

        x = self.f9(x)
        return x

if __name__ == '__mian__':
    x = torch.rand([1, 3, 224, 224])
    model = MyAlexNet()
    y = model(x)
```

##### **2.split_data.py**

将数据集划分为训练集和测试集

```python
import os
from shutil import copy
import random


def mkfile(file):
    if not os.path.exists(file):
        os.makedirs(file)


# 获取data文件夹下所有文件夹名（即需要分类的类名）
file_path = ("PetImages")
flower_class = [cla for cla in os.listdir(file_path)]

# 创建 训练集train 文件夹，并由类名在其目录下创建5个子目录
mkfile('data/train')
for cla in flower_class:
    mkfile('data/train/' + cla)

# 创建 验证集val 文件夹，并由类名在其目录下创建子目录
mkfile('data/val')
for cla in flower_class:
    mkfile('data/val/' + cla)

# 划分比例，训练集 : 验证集 = 8 : 2
split_rate = 0.2

# 遍历所有类别的全部图像并按比例分成训练集和验证集
for cla in flower_class:
    cla_path = file_path + '/' + cla + '/'  # 某一类别的子目录
    images = os.listdir(cla_path)  # iamges 列表存储了该目录下所有图像的名称
    num = len(images)
    eval_index = random.sample(images, k=int(num * split_rate))  # 从images列表中随机抽取 k 个图像名称
    for index, image in enumerate(images):
        # eval_index 中保存验证集val的图像名称
        if image in eval_index:
            image_path = cla_path + image
            new_path = 'data/val/' + cla
            copy(image_path, new_path)  # 将选中的图像复制到新路径

        # 其余的图像保存在训练集train中
        else:
            image_path = cla_path + image
            new_path = 'data/train/' + cla
            copy(image_path, new_path)
        print("\r[{}] processing [{}/{}]".format(cla, index + 1, num), end="")  # processing bar
    print()

print("processing done!")

```

##### **3.train.py**

```python
import torch
from torch import nn
from net import MyAlexNet
import numpy as np
from torch.optim import lr_scheduler
import os

from torchvision import transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader

import matplotlib.pyplot as plt

# 解决中文显示问题
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False


ROOT_TRAIN = "./data/train"
ROOT_VAL = "./data/val"



# 将图像的像素值归一化到【-1， 1】之间
normalize = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])

train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomVerticalFlip(),
    transforms.ToTensor(),
    normalize])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    normalize])

train_dataset = ImageFolder(ROOT_TRAIN, transform=train_transform)
val_dataset = ImageFolder(ROOT_VAL, transform=val_transform)

train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)


device = 'cuda' if torch.cuda.is_available() else 'cpu'

model = MyAlexNet().to(device)

# 定义一个损失函数
loss_fn = nn.CrossEntropyLoss()

# 定义一个优化器
optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)

# 学习率每隔10轮变为原来的0.5
lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)

# 定义训练函数
def train(dataloader, model, loss_fn, optimizer):
    loss, current, n = 0.0, 0.0, 0
    for batch, (x, y) in enumerate(dataloader):
        image, y = x.to(device), y.to(device)
        output = model(image)
        cur_loss = loss_fn(output, y)
        _, pred = torch.max(output, axis=1)
        cur_acc = torch.sum(y==pred) / output.shape[0]

        # 反向传播
        optimizer.zero_grad()
        cur_loss.backward()
        optimizer.step()
        loss += cur_loss.item()
        current += cur_acc.item()
        n = n+1

    train_loss = loss / n
    train_acc = current / n
    print('train_loss' + str(train_loss))
    print('train_acc' + str(train_acc))
    return train_loss, train_acc

# 定义一个验证函数
def val(dataloader, model, loss_fn):
    # 将模型转化为验证模型
    model.eval()
    loss, current, n = 0.0, 0.0, 0
    with torch.no_grad():
        for batch, (x, y) in enumerate(dataloader):
            image, y = x.to(device), y.to(device)
            output = model(image)
            cur_loss = loss_fn(output, y)
            _, pred = torch.max(output, axis=1)
            cur_acc = torch.sum(y == pred) / output.shape[0]
            loss += cur_loss.item()
            current += cur_acc.item()
            n = n + 1

    val_loss = loss / n
    val_acc = current / n
    print('val_loss' + str(val_loss))
    print('val_acc' + str(val_acc))
    return val_loss, val_acc

# 定义画图函数
def matplot_loss(train_loss, val_loss):
    plt.plot(train_loss, label='train_loss')
    plt.plot(val_loss, label='val_loss')
    plt.legend(loc='best')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.title("训练集和验证集loss值对比图")
    plt.show()

def matplot_acc(train_acc, val_acc):
    plt.plot(train_acc, label='train_acc')
    plt.plot(val_acc, label='val_acc')
    plt.legend(loc='best')
    plt.ylabel('acc')
    plt.xlabel('epoch')
    plt.title("训练集和验证集acc值对比图")
    plt.show()



# 开始训练
loss_train = []
acc_train = []
loss_val = []
acc_val = []


epoch = 20
min_acc = 0
for t in range(epoch):
    lr_scheduler.step()
    print(f"epoch{t+1}\n-----------")
    train_loss, train_acc = train(train_dataloader, model, loss_fn, optimizer)
    val_loss, val_acc = val(val_dataloader, model, loss_fn)

    loss_train.append(train_loss)
    acc_train.append(train_acc)
    loss_val.append(val_loss)
    acc_val.append(val_acc)

    # 保存最好的模型权重
    if val_acc >min_acc:
        folder = 'save_model'
        if not os.path.exists(folder):
            os.mkdir('save_model')
        min_acc = val_acc
        print(f"save best model, 第{t+1}轮")
        torch.save(model.state_dict(), 'save_model/best_model.pth')
    # 保存最后一轮的权重文件
    if t == epoch-1:
        torch.save(model.state_dict(), 'save_model/last_model.pth')

matplot_loss(loss_train, loss_val)
matplot_acc(acc_train, acc_val)
print('Done!')

```

##### **4.test.py**

```python
import torch
from net import MyAlexNet
from torch.autograd import Variable
from torchvision import datasets, transforms
from torchvision.transforms import ToTensor
from torchvision.transforms import ToPILImage
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import os

# 设置数据集的路径
ROOT_TRAIN = "data/train"
ROOT_TEST = "data/val"

# 将图像的像素值归一化到【-1， 1】之间
normalize = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])

train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomVerticalFlip(),
    transforms.ToTensor(),
    normalize])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

train_dataset = ImageFolder(ROOT_TRAIN, transform=train_transform)
val_dataset = ImageFolder(ROOT_TEST, transform=val_transform)

train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)

device = 'cuda' if torch.cuda.is_available() else 'cpu'

model = MyAlexNet().to(device)

# 加载模型
model.load_state_dict(torch.load("save_model/best_model.pth"))

# 获取预测结果
classes = [
    "cat",
    "dog",
]

# 把张量转化为照片格式
show = ToPILImage()

# 设置猫和狗的图片数量
cat_images = [img for img, label in val_dataset if label == 0]
dog_images = [img for img, label in val_dataset if label == 1]

# 进入到验证阶段
model.eval()

# 选择3张猫和7张狗图片进行验证
num_cats = 3
num_dogs = 7

# 验证猫的图片
for i in range(num_cats):
    x = cat_images[i]
    y = 0  # 猫的标签是0
    img_path = val_dataset.imgs[i][0]  # 获取图片的完整路径
    img_name = os.path.basename(img_path)  # 获取图片的文件名
    print(f'Image Name: {img_name}, Image Path: {img_path}')  # 打印图片名称和路径
    show(x).show()

    # 将图片转换为张量并移动到设备上
    x = Variable(torch.unsqueeze(x, dim=0).float(), requires_grad=True).to(device)

    with torch.no_grad():
        pred = model(x)
        predicted, actual = classes[torch.argmax(pred[0])], classes[y]
        print(f'predicted: "{predicted}", Actual: "{actual}"')

# 验证狗的图片
for i in range(num_dogs):
    x = dog_images[i]
    y = 1  # 狗的标签是1
    img_path = val_dataset.imgs[len(cat_images) + i][0]  # 获取图片的完整路径
    img_name = os.path.basename(img_path)  # 获取图片的文件名
    print(f'Image Name: {img_name}, Image Path: {img_path}')  # 打印图片名称和路径
    show(x).show()

    # 将图片转换为张量并移动到设备上
    x = Variable(torch.unsqueeze(x, dim=0).float(), requires_grad=True).to(device)

    with torch.no_grad():
        pred = model(x)
        predicted, actual = classes[torch.argmax(pred[0])], classes[y]
        print(f'predicted: "{predicted}", Actual: "{actual}"')

```

