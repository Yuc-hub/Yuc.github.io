---
title: "ResNet 深度残差网络搭建教程"
date: 2025-10-23
categories:
  - 教程
tags:
  - 深度学习
  - PyTorch
  - 神经网络
  - ResNet
  - 计算机视觉
toc: true
toc_label: "目录"
toc_sticky: true
header:
  teaser: /assets/images/resnet/resnet-banner.jpg
---

jetson 上搭建 ResNet 深度残差网络

-- 文档内容为学习记录，整理来源于网络，仅用于个人学习

> 本文档共同整理者：zbr1234 

### ResNet搭建

#### 4.1 网络概述

##### 4.1.1 网络亮点：

1. **超深的网络结构（突破1000层）**
2. **提出residual模块**
3. **使用Batch Normalization加速训练（丢弃Dropout正则化）**



##### 4.1.2 模型背景与简介

**问题：随着神经网络的不断加深，一定会带来好处吗？**

**不一定**

<img src="{{ '/assets/images/resnet/image-20250304174855773.png' | relative_url }}" alt="image-20250304174855773" style="zoom:67%;" />

- 蓝色五角星表示**最优值**
- 标有Fi的闭合区域表示函数，闭合区域的面积代表**函数的复杂程度**，在这个区域中能够找到一个**最优的模型**（可以用区域中的一个点来表示，该点到最优值的距离可以用来衡量模型的好坏）

从上图中可以看出，随着函数的复杂度的不断增加，虽然函数的区域面积增大了，但是在该区域中所能找到的最优模型（该区域内的某一点）离最优值的距离可能会越来越远（也就是模型所在的区域随着函数复杂度的增加，逐渐偏离了原来的区域，离最优值越来越远）（**非嵌套函数（non-nested function）**）

解决上述问题（模型走偏）的方法：每一次增加函数复杂度之后函数所覆盖的区域会包含原来函数所在的区域（**嵌套函数（nested function）**），只有当较复杂的函数类包含复杂度较小的函数类时，才能确保提高它的性能。也就是说，增加函数的复杂度只会使函数所覆盖的区域在原有的基础上进行**扩充**，而不会偏离原本存在的区域

对于深度神经网络，如果能将新添加的层训练成**恒等映射（identify function）f(x) = x**，新模型和原模型将同样有效；同时，由于新模型可能得出更优的解来拟合训练数据集，因此添加层似乎更容易降低训练误差。

针对这个问题，**何恺明**等人提出了残差网络**ResNet**，它拿到了**2015年ImageNet图像识别挑战赛**的冠军，并深刻影响了后来深度神经网络的设计

![image-20250304174447354]({{ '/assets/images/resnet/image-20250304174447354.png' | relative_url }})

从中可以看出，ResNet确实解决了随着层数加深但是精度下降的问题



##### 4.1.3 ResNet的核心：残差块

不同层数ResNet大致结构表格：

![image-20250304175808572]({{ '/assets/images/resnet/image-20250304175808572.png' | relative_url }})

这里详细讲解34层的ResNet，下图为34层ResNet的具体卷积过程，以及和先前模型的一个对比，可以看出VGG的深度并没有很高，因为随着深度加深并不会提高精确度，而Resnet就可以用到34层的深度，就是应为每层之间都有残差块。

![image-20250304180832993]({{ '/assets/images/resnet/image-20250304180832993.png' | relative_url }})

注意到卷积层之间的residul有些用实线直接连接，有些用虚线连接，这是两种不同的residual结构，区别在于输入特征矩阵和输出特征矩阵的shape是否一样，shape一样的就是实现直接连接，不一样的就要经过一个尺寸转化。

<img src="{{ '/assets/images/resnet/image-20250304181011008.png' | relative_url }}" alt="image-20250304181011008" style="zoom: 33%;" />



##### 4.1.4 Batch Normalization

<img src="{{ '/assets/images/resnet/image-20250304181819727.png' | relative_url }}" alt="image-20250304181819727" style="zoom:67%;" />



##### 4.1.5 迁移学习

##### 基于共享参数的迁移

基于共享参数的迁移研究的是如何找到源数据和目标数据的空间模型之间的共同参数或者先验分布，从而可以通过进一步处理，达到知识迁移的目的，假设前提是，学习任务中的的每个相关模型会共享一些相同的参数或者先验分布。

<img src="{{ '/assets/images/resnet/367b5e225449311b278e7272f86aad2f.png' | relative_url }}" alt="在这里插入图片描述" style="zoom: 33%;" />

深度学习需要大量的高质量标注数据，Pre-training + fine-tuning 是现在深度学习中一个非常流行的trick，尤其是以图像领域为代表，很多时候会选择预训练的ImageNet对模型进行初始化。

<img src="{{ '/assets/images/resnet/image-20250304211316145.png' | relative_url }}" alt="image-20250304211316145" style="zoom: 33%;" />

举个例子一个图像网络的前几层所学习到的特征可能是识别图片角点信息或者纹理信息这种通用型信息特征，而后面几轮在是比较具体的深度的特征，那么一个模型的前几层通用特征训练出来的权重可以转移到另一个模型作为预权重，以达到加快模型训练的目的。



#### 4.2 实验目的

学习ResNet结构、Batch Normalization以及迁移学习，利用这些实现花朵的图像分类



#### 4.3 搭建过程

##### 4.3.1 文件结构说明

```
ResNet [Test5_resnet]
├── data
│   └── imgs					# 用于存放自己用于预测的图片
├── data_set					# 数据集文件夹
│   └── flower_data
│       ├── flower_photos		# 这个是解压好的花朵数据集文件
│       ├── flower_photos.tgz	# 下载的花朵数据压缩包
│       ├── train				# 这个是划分好的训练集（自动生成）
│       ├── val					# 这个是划分好的验证集（自动生成）
│ 		└── split_data.py		# 划分数据集代码
├── batch_predict.py			# 预测多个图片
├── class_indices.json			# 分类标签（自动生成）
├── load_weights.py				# 加载权重
├── model.py					# ResNet模型
├── predict.py					# 预测单个图片
├── resNet34.pth				# 最终训练出来的权重（自动生成）
├── resnet34-pre.pth			# 加载的预权重（自己下载）
└── train.py					# 训练模型代码
```



##### 4.3.2 数据集的准备

- 在data_set文件夹里面再建一个flower_data文件夹，这个文件里存放下载的花朵数据压缩包flower_photos.tgz，然后解压到当前文件夹。解压办法：右键压缩包后点击Extract Here


（**如果已经存在训练集和验证集就不需要再划分数据集了！**重复操作的话会重复划分数据集，可以删了train和val文件夹及里面的图片后再划分）

- 确认split_data.py里面Flower_data的路径为flower_photos内的路径无误后就可以运行split_data.py


```
data_root = os.path.join(cwd, "flower_data")
```

**分类结果：**

```terminal
[roses] processing [641/641]
[daisy] processing [633/633]
[tulips] processing [799/799]
[dandelion] processing [898/898]
[sunflowers] processing [699/699]
processing done!
```

可以看到flower_photos多了train和val两个文件夹

![ac073f7dae350442f34d4da10701446c]({{ '/assets/images/resnet/ac073f7dae350442f34d4da10701446c.png' | relative_url }})



##### 4.3.3 预权重的准备（选择）

- 编写load_weights.py
- 下载预权重

34层ResNet预权重的下载链接在load_weights.py选择预权重路径旁的注释中著名了（https://download.pytorch.org/models/resnet34-333f7ec4.pth）

```python
	# load pretrain weights
    # download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth
    model_weight_path = "./resnet34-pre.pth"
```

- 将下载的预权重重命名resnet34-pre.pth作为预权重放到工程里头
- 将model_weight_path的路径填为下载并且重命名后的路径
- 运行load_weights.py，就会将预权重加载到模型中



其他层数ResNet模型的的预权重在model.py里面有注明，若要用其他层数的ResNet也可以下载对应的预权重，我们这次使用34层的ResNet就足够了。

```python
def resnet34(num_classes=1000, include_top=True):
    # https://download.pytorch.org/models/resnet34-333f7ec4.pth
    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)


def resnet50(num_classes=1000, include_top=True):
    # https://download.pytorch.org/models/resnet50-19c8e357.pth
    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)


def resnet101(num_classes=1000, include_top=True):
    # https://download.pytorch.org/models/resnet101-5d3b4d8f.pth
    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top)
```



当然也可以选择不使用预权重，就不用下载了，但是代码需要有一点小修改后面训练模型的时候会讲到。



##### 4.3.4 网络搭建

- 确定数据集路径

```python
image_path = "data_set/flower_data"
```

- 选择是否使用预权重

```python
    # option1：使用迁移学习方法，需要下载预权重
    # --------------------------------------------------------------------------------
    net = resnet34()    # 选用34层的残差网络
    # 下载迁移的预训练权重
    # 34层网络预权重下载地址: https://download.pytorch.org/models/resnet34-333f7ec4.pth
    model_weight_path = "./resnet34-pre.pth" # 路径地址
    assert os.path.exists(model_weight_path), "file {} does not exist.".format(model_weight_path)
    net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))
    # for param in net.parameters():
    #     param.requires_grad = False
    # change fc layer structure
    in_channel = net.fc.in_features
    net.fc = nn.Linear(in_channel, 5)
    # --------------------------------------------------------------------------------
    
    # option2： 不使用迁移学习训练模型
    # --------------------------------------------------------------------------------
    # net = resnet34(5)
    # --------------------------------------------------------------------------------
```

若需要使用预权重，选择好之前下载和重命名的resnet34-pre.pth的路径，

若不需要使用预权重就将option1里面的代码全部注释掉，将option2的代码注释取消

若不使用预权重还要修改epoch值，建议大于20，经过实验，可能迭代了40轮还没有使用迁移学习的预权重精准度来的高，这就体现了迁移学习的先进之处。

之后运行train.py后可以看到结果

```terminal
using 3306 images for training, 364 images for validation.
train epoch[1/3] loss:0.868: 100%|██████████| 207/207 [00:59<00:00,  3.47it/s]
valid epoch[1/3]: 100%|██████████| 23/23 [00:02<00:00,  9.30it/s]
[epoch 1] train_loss: 0.506  val_accuracy: 0.896
train epoch[2/3] loss:0.293: 100%|██████████| 207/207 [00:53<00:00,  3.85it/s]
valid epoch[2/3]: 100%|██████████| 23/23 [00:02<00:00,  9.99it/s]
[epoch 2] train_loss: 0.332  val_accuracy: 0.931
train epoch[3/3] loss:0.117: 100%|██████████| 207/207 [00:53<00:00,  3.85it/s]
valid epoch[3/3]: 100%|██████████| 23/23 [00:02<00:00,  9.91it/s]
[epoch 3] train_loss: 0.293  val_accuracy: 0.918
Finished Training
```

可以看到第二轮训练出的模型精度就达到了惊人的93%！



#### 4.4 模型的验证与预测

预测有两种方式，单张图片预测和批量图片预测。

##### 先是两种方式都要设置的 --- predict.py/batch_predict.py

- 选择模型

```
# create model
    model = resnet34(num_classes=5).to(device)
```

我们这里选择的是resnet34对应的是34层的ResNet网络，还有其他的模型原型在model.py的最后面有声明

```python
def resnet34(num_classes=1000, include_top=True):
def resnet50(num_classes=1000, include_top=True):
def resnet101(num_classes=1000, include_top=True):
def resnext50_32x4d(num_classes=1000, include_top=True):
def resnext101_32x8d(num_classes=1000, include_top=True):
```

- 选择训练好的模型权重

```python
 # load model weights
    weights_path = "./resNet34.pth"
```



##### 单张图片预测 --- predict.py

- 设置图片路径

```python
img_path = "data/imgs/daisy.jpg"
```

![62349fc6e5a214823d644825130c05cc]({{ '/assets/images/resnet/62349fc6e5a214823d644825130c05cc.jpeg' | relative_url }})

- 运行predict.py,得到预测结果。

```
class: daisy        prob: 0.997
class: dandelion    prob: 4.77e-06
class: roses        prob: 0.00158
class: sunflowers   prob: 1.08e-05
class: tulips       prob: 0.0013
```

- 这个表示了这种图片为这五种分类的概率，从中可以看到为daisy的概率最大，有99.7%，这个预测结果正确。



##### 批量图片预测 --- batch_predict.py

设置遍历预测的图像文件夹路径

```python
# 指向需要遍历预测的图像文件夹
imgs_root = "data/imgs"
```

- 设置每次预测时将多少张图片打包成一个batch（根据自己要测试图片个数决定，建议小于10）

```python
batch_size = 5  # 每次预测时将多少张图片打包成一个batch
```

- 运行batch_predict.py

```terminal
image: data/imgs/roses.jpg  class: roses  prob: 1.0
image: data/imgs/sunflowers.jpg  class: sunflowers  prob: 1.0
image: data/imgs/tulips.jpg  class: tulips  prob: 1.0
image: data/imgs/tulips1.jpg  class: tulips  prob: 1.0
image: data/imgs/sunflowers1.jpg  class: sunflowers  prob: 1.0
image: data/imgs/dandelion1.jpg  class: dandelion  prob: 0.995
image: data/imgs/daisy.jpg  class: daisy  prob: 0.991
image: data/imgs/daisy2.jpg  class: daisy  prob: 0.999
image: data/imgs/rose.jpg  class: roses  prob: 0.919
image: data/imgs/dandelion.jpg  class: dandelion  prob: 0.86
```

从网上下载测试的10张图片结果全对！

#### 4.5 代码附录

##### **1.split.py**

```python
import os
from shutil import copy, rmtree
import random


def mk_file(file_path: str):
    if os.path.exists(file_path):
        # 如果文件夹存在，则先删除原文件夹在重新创建
        rmtree(file_path)
    os.makedirs(file_path)


def main():
    # 保证随机可复现
    random.seed(0)

    # 将数据集中10%的数据划分到验证集中
    split_rate = 0.1

    # 指向你解压后的flower_photos文件夹
    cwd = os.getcwd()
    data_root = os.path.join(cwd, "flower_data")
    origin_flower_path = os.path.join(data_root, "flower_photos")
    assert os.path.exists(origin_flower_path), "path '{}' does not exist.".format(origin_flower_path)

    flower_class = [cla for cla in os.listdir(origin_flower_path)
                    if os.path.isdir(os.path.join(origin_flower_path, cla))]

    # 建立保存训练集的文件夹
    train_root = os.path.join(data_root, "train")
    mk_file(train_root)
    for cla in flower_class:
        # 建立每个类别对应的文件夹
        mk_file(os.path.join(train_root, cla))

    # 建立保存验证集的文件夹
    val_root = os.path.join(data_root, "val")
    mk_file(val_root)
    for cla in flower_class:
        # 建立每个类别对应的文件夹
        mk_file(os.path.join(val_root, cla))

    for cla in flower_class:
        cla_path = os.path.join(origin_flower_path, cla)
        images = os.listdir(cla_path)
        num = len(images)
        # 随机采样验证集的索引
        eval_index = random.sample(images, k=int(num*split_rate))
        for index, image in enumerate(images):
            if image in eval_index:
                # 将分配至验证集中的文件复制到相应目录
                image_path = os.path.join(cla_path, image)
                new_path = os.path.join(val_root, cla)
                copy(image_path, new_path)
            else:
                # 将分配至训练集中的文件复制到相应目录
                image_path = os.path.join(cla_path, image)
                new_path = os.path.join(train_root, cla)
                copy(image_path, new_path)
            print("\r[{}] processing [{}/{}]".format(cla, index+1, num), end="")  # processing bar
        print()

    print("processing done!")


if __name__ == '__main__':
    main()

```

##### **2.model.py**

```python
import torch.nn as nn
import torch

# BasicBlock对应的是18层和34层的网络结构
class BasicBlock(nn.Module):
    # expansion对应残差结构主分支采用卷积核的个数有没有发生变化
    expansion = 1   # 18和32层网络的的第一层和第二层卷积核个数一模一样，倍数为1，故设置为1

    # 定义初始函数
    # in_channel：输入特征矩阵的深度
    # out_channel：输出特征矩阵深度（对应主分支上卷积核的个数）
    # stride：默认取1
    # downsample：下采样参数，默认取none，该参数对应采用的是实线残差结构还是虚线残差结构
    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):
        super(BasicBlock, self).__init__()
        # 第一层卷积
        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,
                               kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channel)  # 批归一化
        self.relu = nn.ReLU()   # 激活函数
        # 第二层卷积
        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,
                               kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channel)  # 批归一化
        self.downsample = downsample    # 下采样，主要用于调整特征图的尺寸

    # 定义正向传播
    def forward(self, x):
        identity = x    # 保留输入，用于残差连接
        if self.downsample is not None:
            identity = self.downsample(x)   # 如果有下采样，调整输入的尺寸

        # 第一层卷积
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        # 第二层卷积
        out = self.conv2(out)
        out = self.bn2(out)

        out += identity  # 残差连接
        out = self.relu(out)    # 激活函数

        return out  # 返回输出

# Bottleneck对应50、101和152层的残差结构
class Bottleneck(nn.Module):
    """
    注意：原论文中，在虚线残差结构的主分支上，第一个1x1卷积层的步距是2，第二个3x3卷积层步距是1。
    但在pytorch官方实现过程中是第一个1x1卷积层的步距是1，第二个3x3卷积层步距是2，
    这么做的好处是能够在top1上提升大概0.5%的准确率。
    可参考Resnet v1.5 https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch
    """
    expansion = 4   # expansion是瓶颈结构中的扩展因子，用于计算输出通道数

    def __init__(self, in_channel, out_channel, stride=1, downsample=None,
                 groups=1, width_per_group=64):
        super(Bottleneck, self).__init__()

        # 根据宽度和组数计算每个卷积层的通道数
        width = int(out_channel * (width_per_group / 64.)) * groups

        # 第一个1x1卷积层，减少通道数
        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width,
                               kernel_size=1, stride=1, bias=False)  # squeeze channels
        self.bn1 = nn.BatchNorm2d(width)
        # -----------------------------------------
        # 第二个3x3卷积层，进行特征提取
        self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups,
                               kernel_size=3, stride=stride, bias=False, padding=1)
        self.bn2 = nn.BatchNorm2d(width)
        # -----------------------------------------
        # 第三个1x1卷积层，恢复通道数
        self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel*self.expansion,
                               kernel_size=1, stride=1, bias=False)  # unsqueeze channels
        self.bn3 = nn.BatchNorm2d(out_channel*self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample

    def forward(self, x):
        identity = x    # 保留输入，用于残差连接
        if self.downsample is not None:
            identity = self.downsample(x)   # 如果有下采样，调整输入的尺寸

        # 第一个1x1卷积
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        # 第二个3x3卷积
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        # 第三个1x1卷积
        out = self.conv3(out)
        out = self.bn3(out)

        # 定义ResNet整个网络的框架
        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):

    def __init__(self,
                 block,                 # 根据不同层数网络选用不同的Block。18和34选BasicBlock，50、101和152选Bottleneck
                 blocks_num,            # 定义残差结构数目，例如34层残差结构是[3,4,6,3]
                 num_classes=1000,      # 训练集的个数
                 include_top=True,      # 用于在ResNet网络基础上去搭建更复杂网路，这里用不到，默认是ture
                 groups=1,
                 width_per_group=64):
        super(ResNet, self).__init__()
        self.include_top = include_top
        self.in_channel = 64 # 3*3 maxpool后的输入特征矩阵深度，不同深度的残差结构都是64

        self.groups = groups
        self.width_per_group = width_per_group

        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2,
                               padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(self.in_channel)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, blocks_num[0])
        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)
        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)
        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)
        if self.include_top:
            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # output size = (1, 1)
            self.fc = nn.Linear(512 * block.expansion, num_classes)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')

    def _make_layer(self, block, channel, block_num, stride=1):
        downsample = None
        if stride != 1 or self.in_channel != channel * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(channel * block.expansion))

        layers = []
        layers.append(block(self.in_channel,
                            channel,
                            downsample=downsample,
                            stride=stride,
                            groups=self.groups,
                            width_per_group=self.width_per_group))
        self.in_channel = channel * block.expansion

        for _ in range(1, block_num):
            layers.append(block(self.in_channel,
                                channel,
                                groups=self.groups,
                                width_per_group=self.width_per_group))

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        if self.include_top:
            x = self.avgpool(x)
            x = torch.flatten(x, 1)
            x = self.fc(x)

        return x

# 这里就是根据不同层数的残差网络定义初始化函数的参数
"""
class ResNet(nn.Module):

    def __init__(self,
                 block,                 # 根据不同层数网络选用不同的Block。18和34选BasicBlock，50、101和152选Bottleneck
                 blocks_num,            # 定义残差结构数目，例如34层残差结构是[3,4,6,3]
                 num_classes=1000,      # 训练集的个数
                 include_top=True)      # 用于在ResNet网络基础上去搭建更复杂网路，这里用不到，默认是ture
"""
def resnet34(num_classes=1000, include_top=True):
    # https://download.pytorch.org/models/resnet34-333f7ec4.pth
    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)


def resnet50(num_classes=1000, include_top=True):
    # https://download.pytorch.org/models/resnet50-19c8e357.pth
    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)


def resnet101(num_classes=1000, include_top=True):
    # https://download.pytorch.org/models/resnet101-5d3b4d8f.pth
    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top)


def resnext50_32x4d(num_classes=1000, include_top=True):
    # https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth
    groups = 32
    width_per_group = 4
    return ResNet(Bottleneck, [3, 4, 6, 3],
                  num_classes=num_classes,
                  include_top=include_top,
                  groups=groups,
                  width_per_group=width_per_group)


def resnext101_32x8d(num_classes=1000, include_top=True):
    # https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth
    groups = 32
    width_per_group = 8
    return ResNet(Bottleneck, [3, 4, 23, 3],
                  num_classes=num_classes,
                  include_top=include_top,
                  groups=groups,
                  width_per_group=width_per_group)

```

##### **3.load_weights.py**

```python
import os
import torch
import torch.nn as nn
from model import resnet34


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    # load pretrain weights
    # download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth
    model_weight_path = "./resnet34-pre.pth"
    assert os.path.exists(model_weight_path), "file {} does not exist.".format(model_weight_path)

    # option1
    net = resnet34()
    net.load_state_dict(torch.load(model_weight_path))
    net.to(device)
    # change fc layer structure
    in_channel = net.fc.in_features
    net.fc = nn.Linear(in_channel, 5)

    # option2
    # net = resnet34(num_classes=5)
    # pre_weights = torch.load(model_weight_path, map_location=device)
    # del_key = []
    # for key, _ in pre_weights.items():
    #     if "fc" in key:
    #         del_key.append(key)
    #
    # for key in del_key:
    #     del pre_weights[key]
    #
    # missing_keys, unexpected_keys = net.load_state_dict(pre_weights, strict=False)
    # print("[missing_keys]:", *missing_keys, sep="\n")
    # print("[unexpected_keys]:", *unexpected_keys, sep="\n")


if __name__ == '__main__':
    main()

```

##### **4.train.py**

```python
import os
import sys
import json

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, datasets
from tqdm import tqdm

from model import resnet34

# 按住Ctrol点击下面的resnet可以查看官方文档
import torchvision.models.resnet



def main():
    # 若有cuda自动使用cuda
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("using {} device.".format(device))

    # 数据处理
    data_transform = {
        "train": transforms.Compose([transforms.RandomResizedCrop(224),
                                     transforms.RandomHorizontalFlip(),
                                     transforms.ToTensor(),
                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),
        "val": transforms.Compose([transforms.Resize(256),
                                   transforms.CenterCrop(224),
                                   transforms.ToTensor(),
                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}

    # 数据集路径
    image_path = "data_set/flower_data"
    assert os.path.exists(image_path), "{} path does not exist.".format(image_path)
    # 自动生成训练集和验证集路径
    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, "train"),
                                         transform=data_transform["train"])
    train_num = len(train_dataset)

    # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}
    flower_list = train_dataset.class_to_idx
    cla_dict = dict((val, key) for key, val in flower_list.items())
    # write dict into json file
    json_str = json.dumps(cla_dict, indent=4)
    with open('class_indices.json', 'w') as json_file:
        json_file.write(json_str)

    batch_size = 16
    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers
    print('Using {} dataloader workers every process'.format(nw))

    train_loader = torch.utils.data.DataLoader(train_dataset,
                                               batch_size=batch_size, shuffle=True,
                                               num_workers=nw)  # linux系统将线程个数Num_workers设置成大于0的数可以加速图像与处理过程，windows必须为0

    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, "val"),
                                            transform=data_transform["val"])
    val_num = len(validate_dataset)
    validate_loader = torch.utils.data.DataLoader(validate_dataset,
                                                  batch_size=batch_size, shuffle=False,
                                                  num_workers=nw)

    print("using {} images for training, {} images for validation.".format(train_num,
                                                                           val_num))



    # 这里的模型训练有两种选择

    # option1：使用迁移学习方法，需要下载预权重
    # -------------------------------------------------------------------------------------------
    net = resnet34()    # 选用34层的残差网络
    # 下载迁移的预训练权重
    # 34层网络预权重下载地址: https://download.pytorch.org/models/resnet34-333f7ec4.pth
    model_weight_path = "./resnet34-pre.pth" # 路径地址
    assert os.path.exists(model_weight_path), "file {} does not exist.".format(model_weight_path)
    net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))
    # for param in net.parameters():
    #     param.requires_grad = False
    # change fc layer structure
    in_channel = net.fc.in_features
    net.fc = nn.Linear(in_channel, 5)
    # --------------------------------------------------------------------------------------------

    # option2： 不使用迁移学习训练模型
    # --------------------------------------------------------------------------------------------
    # net = resnet34(5)
    # --------------------------------------------------------------------------------------------

    net.to(device)

    # 定义损失函数
    loss_function = nn.CrossEntropyLoss()

    # construct an optimizer
    params = [p for p in net.parameters() if p.requires_grad]
    optimizer = optim.Adam(params, lr=0.0001)

    # 训练迭代次数
    epochs = 3      # 如果使用了预权重，迭代3次也足够了，若果没有预权重，建议设置20以上
    best_acc = 0.0
    save_path = './resNet34.pth'
    train_steps = len(train_loader)
    for epoch in range(epochs):
        # train
        net.train()
        running_loss = 0.0
        train_bar = tqdm(train_loader, file=sys.stdout)
        for step, data in enumerate(train_bar):
            images, labels = data
            optimizer.zero_grad()
            logits = net(images.to(device))
            loss = loss_function(logits, labels.to(device))
            loss.backward()
            optimizer.step()

            # 打印数据
            running_loss += loss.item()

            train_bar.desc = "train epoch[{}/{}] loss:{:.3f}".format(epoch + 1,
                                                                     epochs,
                                                                     loss)

        # validate
        net.eval()
        acc = 0.0  # accumulate accurate number / epoch
        with torch.no_grad():
            val_bar = tqdm(validate_loader, file=sys.stdout)
            for val_data in val_bar:
                val_images, val_labels = val_data
                outputs = net(val_images.to(device))
                # loss = loss_function(outputs, test_labels)
                predict_y = torch.max(outputs, dim=1)[1]
                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()

                val_bar.desc = "valid epoch[{}/{}]".format(epoch + 1,
                                                           epochs)

        val_accurate = acc / val_num
        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %
              (epoch + 1, running_loss / train_steps, val_accurate))

        if val_accurate > best_acc:
            best_acc = val_accurate
            torch.save(net.state_dict(), save_path)

    print('Finished Training')


if __name__ == '__main__':
    main()

```

##### **5.predict.py**

```python
import os
import json

import torch
from PIL import Image
from torchvision import transforms
import matplotlib.pyplot as plt

from model import resnet34


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    data_transform = transforms.Compose(
        [transforms.Resize(256),
         transforms.CenterCrop(224),
         transforms.ToTensor(),
         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])

    # load image
    img_path = "data/imgs/daisy.jpg"
    assert os.path.exists(img_path), "file: '{}' dose not exist.".format(img_path)
    img = Image.open(img_path)
    plt.imshow(img)
    # [N, C, H, W]
    img = data_transform(img)
    # expand batch dimension
    img = torch.unsqueeze(img, dim=0)

    # read class_indict
    json_path = './class_indices.json'
    assert os.path.exists(json_path), "file: '{}' dose not exist.".format(json_path)

    with open(json_path, "r") as f:
        class_indict = json.load(f)

    # create model
    model = resnet34(num_classes=5).to(device)

    # load model weights
    weights_path = "./resNet34.pth"
    assert os.path.exists(weights_path), "file: '{}' dose not exist.".format(weights_path)
    model.load_state_dict(torch.load(weights_path, map_location=device))

    # prediction
    model.eval()
    with torch.no_grad():
        # predict class
        output = torch.squeeze(model(img.to(device))).cpu()

        # softmaxdedaogailvfenbu
        predict = torch.softmax(output, dim=0)
        predict_cla = torch.argmax(predict).numpy()

    print_res = "class: {}   prob: {:.3}".format(class_indict[str(predict_cla)],
                                                 predict[predict_cla].numpy())
    plt.title(print_res)
    for i in range(len(predict)):
        print("class: {:10}   prob: {:.3}".format(class_indict[str(i)],
                                                  predict[i].numpy()))
    plt.show()


if __name__ == '__main__':
    main()

```

##### **6.batch_predict.py**

```python
import os
import json

import torch
from PIL import Image
from torchvision import transforms

from model import resnet34


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    data_transform = transforms.Compose(
        [transforms.Resize(256),
         transforms.CenterCrop(224),
         transforms.ToTensor(),
         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])

    # load image
    # 指向需要遍历预测的图像文件夹
    imgs_root = "data/imgs"
    assert os.path.exists(imgs_root), f"file: '{imgs_root}' dose not exist."
    # 读取指定文件夹下所有jpg图像路径
    img_path_list = [os.path.join(imgs_root, i) for i in os.listdir(imgs_root) if i.endswith(".jpg")]

    # read class_indict
    json_path = './class_indices.json'
    assert os.path.exists(json_path), f"file: '{json_path}' dose not exist."

    json_file = open(json_path, "r")
    class_indict = json.load(json_file)

    # create model
    model = resnet34(num_classes=5).to(device)

    # load model weights
    weights_path = "./resNet34.pth"
    assert os.path.exists(weights_path), f"file: '{weights_path}' dose not exist."
    model.load_state_dict(torch.load(weights_path, map_location=device))

    # prediction
    model.eval()
    batch_size = 5  # 每次预测时将多少张图片打包成一个batch
    with torch.no_grad():
        for ids in range(0, len(img_path_list) // batch_size):
            img_list = []
            for img_path in img_path_list[ids * batch_size: (ids + 1) * batch_size]:
                assert os.path.exists(img_path), f"file: '{img_path}' dose not exist."
                img = Image.open(img_path)
                img = data_transform(img)
                img_list.append(img)

            # batch img
            # 将img_list列表中的所有图像打包成一个batch
            batch_img = torch.stack(img_list, dim=0)
            # predict class
            output = model(batch_img.to(device)).cpu()
            predict = torch.softmax(output, dim=1)
            probs, classes = torch.max(predict, dim=1)

            for idx, (pro, cla) in enumerate(zip(probs, classes)):
                print("image: {}  class: {}  prob: {:.3}".format(img_path_list[ids * batch_size + idx],
                                                                 class_indict[str(cla.numpy())],
                                                                 pro.numpy()))


if __name__ == '__main__':
    main()

```

